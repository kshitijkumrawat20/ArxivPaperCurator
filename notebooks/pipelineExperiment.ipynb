{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f45aadbe",
   "metadata": {},
   "source": [
    "## Phase 2: arXiv API Integration & PDF Processing\n",
    "\n",
    "### Core Objectives\n",
    "- arXiv API Integration: Build a robust client with rate limiting and retry logic\n",
    "- PDF Processing Pipeline: Download and parse scientific PDFs with structured content extraction\n",
    "- Database Storage: Persist paper metadata and content in PostgreSQL\n",
    "- Error Handling: Implement comprehensive error handling and graceful degradation\n",
    "- Automation Ready: Prepare components for Airflow orchestration\n",
    "\n",
    "### ðŸ”§ What We'll Test In This Notebook\n",
    "- arXiv API Client - Fetch CS.AI papers with proper rate limiting\n",
    "- PDF Download System - Download and cache PDFs with error handling\n",
    "- Docling PDF Parser - Extract structured content (sections, tables, figures)\n",
    "- Database Integration - Store and retrieve papers from PostgreSQL\n",
    "- Complete Pipeline - End-to-end processing from arXiv to database\n",
    "- Production Readiness - Error handling, logging, and performance metrics\n",
    "### ðŸ“Š Success Metrics\n",
    "- arXiv API calls succeed with proper rate limiting\n",
    "- PDF download and caching works reliably\n",
    "- Docling extracts structured content from scientific PDFs\n",
    "- Database stores complete paper metadata\n",
    "- Pipeline handles errors gracefully and continues processing\n",
    "- All components ready for Airflow automation (Week 2+)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b7d7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEEK 2 CONTAINER & SERVICE HEALTH CHECK\n",
      "==================================================\n",
      "Project root: /teamspace/studios/this_studio/ArxivPaperCurator\n"
     ]
    }
   ],
   "source": [
    "# Check if Fresh Containers are Built and All Services Healthy\n",
    "import subprocess\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"WEEK 2 CONTAINER & SERVICE HEALTH CHECK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Find project root\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == \"notebooks\" and current_dir.parent.name == \"ArxivPaperCurator\":\n",
    "    project_root = current_dir.parent\n",
    "elif (current_dir / \"compose.yml\").exists():\n",
    "    project_root = current_dir\n",
    "else:\n",
    "    print(\"âœ— Could not find project root\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.13.7\n",
      "Environment: /teamspace/studios/this_studio/ArxivPaperCurator/.venv/bin/python\n"
     ]
    }
   ],
   "source": [
    "# Environment Check\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"Python Version: {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")\n",
    "print(f\"Environment: {sys.executable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4153c8e5",
   "metadata": {},
   "source": [
    "### Service Health Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e526f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Checking container status...\n",
      "âœ“ Containers are running:\n",
      "   NAME                        IMAGE                                            COMMAND                   SERVICE                 CREATED       STATUS                   PORTS\n",
      "   rag-airflow                 apache/airflow:3.0.3                             \"/bin/bash -c '\\n  piâ€¦\"   airflow                 2 hours ago   Up 2 hours (unhealthy)   0.0.0.0:8080->8080/tcp, :::8080->8080/tcp\n",
      "   rag-api                     arxivpapercurator-api                            \"uvicorn src.main:apâ€¦\"    api                     2 hours ago   Up 2 hours (unhealthy)   0.0.0.0:8000->8000/tcp, :::8000->8000/tcp\n",
      "   rag-ollama                  ollama/ollama:0.11.2                             \"/bin/ollama serve\"       ollama                  2 hours ago   Up 2 hours (healthy)     0.0.0.0:11434->11434/tcp, :::11434->11434/tcp\n",
      "   rag-opensearch              opensearchproject/opensearch:2.19.0              \"./opensearch-dockerâ€¦\"    opensearch              2 hours ago   Up 2 hours (healthy)     0.0.0.0:9200->9200/tcp, :::9200->9200/tcp, 9300/tcp, 0.0.0.0:9600->9600/tcp, :::9600->9600/tcp, 9650/tcp\n",
      "   rag-opensearch-dashboards   opensearchproject/opensearch-dashboards:2.19.0   \"./opensearch-dashboâ€¦\"    opensearch-dashboards   2 hours ago   Up 2 hours (healthy)     0.0.0.0:5601->5601/tcp, :::5601->5601/tcp\n",
      "   rag-postgres                postgres:16-alpine                               \"docker-entrypoint.sâ€¦\"    postgres                2 hours ago   Up 2 hours (healthy)     0.0.0.0:5432->5432/tcp, :::5432->5432/tcp\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check if containers are built and running\n",
    "print(\"\\n1. Checking container status...\")\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"docker\", \"compose\", \"ps\", \"--format\", \"table\"],\n",
    "        cwd=str(project_root),\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=10\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0 and result.stdout.strip():\n",
    "        print(\"âœ“ Containers are running:\")\n",
    "        for line in result.stdout.strip().split('\\n'):\n",
    "            print(f\"   {line}\")\n",
    "    else:\n",
    "        print(\"âœ— No containers running or docker compose failed\")\n",
    "        print(\"Please run the build commands from the markdown cell above\")\n",
    "        exit()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error checking containers: {e}\")\n",
    "    print(\"Please run the build commands from the markdown cell above\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Checking service health...\n",
      "âœ“ FastAPI: Healthy\n",
      "âœ“ PostgreSQL (via API): Healthy\n",
      "âœ“ Ollama: Healthy\n",
      "âœ“ OpenSearch: Healthy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Airflow: Healthy\n",
      "\n",
      "==================================================\n",
      "âœ“ ALL SERVICES HEALTHY! Ready for Week 2 development.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Check all service health (corrected endpoints)\n",
    "print(\"\\n2. Checking service health...\")\n",
    "services_to_test = {\n",
    "    \"FastAPI\": \"https://8000-01khp40rhz7zc0vjm8t9gsh5j1.cloudspaces.litng.ai/api/v1/ping/health\",\n",
    "    \"PostgreSQL (via API)\": \"https://8000-01khp40rhz7zc0vjm8t9gsh5j1.cloudspaces.litng.ai/api/v1/ping/health\", \n",
    "    \"Ollama\": \"https://11434-01khp40rhz7zc0vjm8t9gsh5j1.cloudspaces.litng.ai/api/version\",\n",
    "    \"OpenSearch\": \"https://9200-01khp40rhz7zc0vjm8t9gsh5j1.cloudspaces.litng.ai/_cluster/health\",\n",
    "    \"Airflow\": \"https://8080-01khp40rhz7zc0vjm8t9gsh5j1.cloudspaces.litng.ai/api/v2/monitor/health\"\n",
    "}\n",
    "\n",
    "all_healthy = True\n",
    "for service_name, url in services_to_test.items():\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"âœ“ {service_name}: Healthy\")\n",
    "        else:\n",
    "            print(f\"âœ— {service_name}: HTTP {response.status_code}\")\n",
    "            all_healthy = False\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(f\"âœ— {service_name}: Not accessible\")\n",
    "        all_healthy = False\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— {service_name}: {type(e).__name__}\")\n",
    "        all_healthy = False\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "if all_healthy:\n",
    "    print(\"âœ“ ALL SERVICES HEALTHY! Ready for Week 2 development.\")\n",
    "else:\n",
    "    print(\"âœ— Some services need attention.\")\n",
    "    print(\"If you just rebuilt containers, wait 1-2 minutes and run this cell again.\")\n",
    "    print(\"Airflow and OpenSearch take longest to start up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "airflow_password = \"FkfGnM9ZPup7YTre\"\n",
    "airflow_usernmae = \"admin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a1e4aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/teamspace/studios/this_studio/ArxivPaperCurator/notebooks'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71938182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/ArxivPaperCurator\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5276f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING ARXIV API CLIENT\n",
      "========================================\n",
      "âœ“ Client created: https://export.arxiv.org/api/query\n",
      "   Rate limit: 3.0s\n",
      "   Max results: 100\n",
      "   Category: cs.AI\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Import our arXiv client\n",
    "from src.services.arxiv.factory import make_arxiv_client\n",
    "\n",
    "print(\"TESTING ARXIV API CLIENT\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create client\n",
    "arxiv_client = make_arxiv_client()\n",
    "print(f\"âœ“ Client created: {arxiv_client.base_url}\")\n",
    "print(f\"   Rate limit: {arxiv_client.rate_limit_delay}s\")\n",
    "print(f\"   Max results: {arxiv_client.max_results_per_query}\")\n",
    "print(f\"   Category: {arxiv_client.search_category}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d5173c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: Fetch Recent CS.AI Papers\n",
      "âœ“ Fetched 2 papers\n",
      "   1. [2602.16708v1] Policy Compiler for Secure Agentic Systems...\n",
      "      Authors: Nils Palumbo, Sarthak Choudhary...\n",
      "      Categories: \n",
      "      Published: 2026-02-18T18:57:12Z\n",
      "\n",
      "   2. [2602.16703v1] Measuring Mid-2025 LLM-Assistance on Novice Performance in B...\n",
      "      Authors: Shen Zhou Hong, Alex Kleinman...\n",
      "      Categories: \n",
      "      Published: 2026-02-18T18:51:28Z\n",
      "\n"
     ]
    }
   ],
   "source": [
    "async def test_paper_fetching():\n",
    "    \"\"\"Test fetching papers from arXiv with rate limiting.\"\"\"\n",
    "    \n",
    "    print(\"Test 1: Fetch Recent CS.AI Papers\")\n",
    "    try:\n",
    "        papers = await arxiv_client.fetch_papers(\n",
    "            max_results=2, \n",
    "            sort_by=\"submittedDate\",\n",
    "            sort_order=\"descending\"\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ“ Fetched {len(papers)} papers\")\n",
    "        \n",
    "        if papers:\n",
    "            for i, paper in enumerate(papers[:2], 1):\n",
    "                print(f\"   {i}. [{paper.arxiv_id}] {paper.title[:60]}...\")\n",
    "                print(f\"      Authors: {', '.join(paper.authors[:2])}{'...' if len(paper.authors) > 2 else ''}\")\n",
    "                print(f\"      Categories: {', '.join(paper.categories)}\")\n",
    "                print(f\"      Published: {paper.published_date}\")\n",
    "                print()\n",
    "        \n",
    "        return papers\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error fetching papers: {e}\")\n",
    "        if \"503\" in str(e):\n",
    "            print(\"   arXiv API temporarily unavailable (normal)\")\n",
    "            print(\"   Rate limiting and error handling working correctly\")\n",
    "        return []\n",
    "\n",
    "# Run the test\n",
    "papers = await test_paper_fetching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a13d614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 2: Date Range Filtering\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Date filtering test: 2 papers from 20250808-20250809\n",
      "   1. [2508.07111v1] Investigating Intersectional Bias in Large Language Models u...\n",
      "      Authors: Falaah Arif Khan, Nivedha Sivakumar...\n",
      "      Categories: \n",
      "      Published: 2025-08-09T22:24:40Z\n",
      "\n",
      "   2. [2508.07107v2] Designing a Feedback-Driven Decision Support System for Dyna...\n",
      "      Authors: Timothy Oluwapelumi Adeyemi, Nadiah Fahad AlOtaibi\n",
      "      Categories: \n",
      "      Published: 2025-08-09T21:24:54Z\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Date Filtering\n",
    "async def test_date_filtering():\n",
    "    \"\"\"Test date range filtering functionality.\"\"\"\n",
    "    \n",
    "    print(\"Test 2: Date Range Filtering\")\n",
    "    \n",
    "    # Use specific dates: \n",
    "    from_date = \"20250808\"  \n",
    "    to_date = \"20250809\"    \n",
    "    try:\n",
    "        date_papers = await arxiv_client.fetch_papers(\n",
    "            max_results=2,\n",
    "            from_date=from_date,\n",
    "            to_date=to_date\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ“ Date filtering test: {len(date_papers)} papers from {from_date}-{to_date}\")\n",
    "        \n",
    "        if date_papers:\n",
    "            for i, paper in enumerate(date_papers, 1):\n",
    "                print(f\"   {i}. [{paper.arxiv_id}] {paper.title[:60]}...\")\n",
    "                print(f\"      Authors: {', '.join(paper.authors[:2])}{'...' if len(paper.authors) > 2 else ''}\")\n",
    "                print(f\"      Categories: {', '.join(paper.categories)}\")\n",
    "                print(f\"      Published: {paper.published_date}\")\n",
    "                print()\n",
    "        \n",
    "        return date_papers\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Date filtering error: {e}\")\n",
    "        return []\n",
    "\n",
    "# Run date filtering test\n",
    "date_papers = await test_date_filtering()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25683731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ArxivPaper(arxiv_id='2508.07111v1', title='Investigating Intersectional Bias in Large Language Models using Confidence Disparities in Coreference Resolution', authors=['Falaah Arif Khan', 'Nivedha Sivakumar', 'Yinong Oliver Wang', 'Katherine Metcalf', 'Cezanne Camacho', 'Barry-John Theobald', 'Luca Zappella', 'Nicholas Apostoloff'], abstract='Large language models (LLMs) have achieved impressive performance, leading to their widespread adoption as decision-support tools in resource-constrained contexts like hiring and admissions. There is, however, scientific consensus that AI systems can reflect and exacerbate societal biases, raising concerns about identity-based harm when used in critical social contexts. Prior work has laid a solid foundation for assessing bias in LLMs by evaluating demographic disparities in different language reasoning tasks. In this work, we extend single-axis fairness evaluations to examine intersectional bias, recognizing that when multiple axes of discrimination intersect, they create distinct patterns of disadvantage. We create a new benchmark called WinoIdentity by augmenting the WinoBias dataset with 25 demographic markers across 10 attributes, including age, nationality, and race, intersected with binary gender, yielding 245,700 prompts to evaluate 50 distinct bias patterns. Focusing on harms of omission due to underrepresentation, we investigate bias through the lens of uncertainty and propose a group (un)fairness metric called Coreference Confidence Disparity which measures whether models are more or less confident for some intersectional identities than others. We evaluate five recently published LLMs and find confidence disparities as high as 40% along various demographic attributes including body type, sexual orientation and socio-economic status, with models being most uncertain about doubly-disadvantaged identities in anti-stereotypical settings. Surprisingly, coreference confidence decreases even for hegemonic or privileged markers, indicating that the recent impressive performance of LLMs is more likely due to memorization than logical reasoning. Notably, these are two independent failures in value alignment and validity that can compound to cause social harm.', categories=[], published_date='2025-08-09T22:24:40Z', pdf_url='https://arxiv.org/pdf/2508.07111v1'),\n",
       " ArxivPaper(arxiv_id='2508.07107v2', title='Designing a Feedback-Driven Decision Support System for Dynamic Student Intervention', authors=['Timothy Oluwapelumi Adeyemi', 'Nadiah Fahad AlOtaibi'], abstract='Accurate prediction of student performance is essential for enabling timely academic interventions. However, most machine learning models used in educational settings are static and lack the ability to adapt when new data such as post-intervention outcomes become available. To address this limitation, we propose a Feedback-Driven Decision Support System (DSS) with a closed-loop architecture that enables continuous model refinement. The system employs a LightGBM-based regressor with incremental retraining, allowing educators to input updated student performance data, which automatically triggers model updates. This adaptive mechanism enhances prediction accuracy by learning from real-world academic progress over time.   The platform features a Flask-based web interface to support real-time interaction and integrates SHAP (SHapley Additive exPlanations) for model interpretability, ensuring transparency and trustworthiness in predictions. Experimental results demonstrate a 10.7% reduction in RMSE after retraining, with consistent upward adjustments in predicted scores for students who received interventions. By transforming static predictive models into self-improving systems, our approach advances educational analytics toward human-centered, data-driven, and responsive artificial intelligence. The framework is designed for seamless integration into Learning Management Systems (LMS) and institutional dashboards, facilitating practical deployment in real educational environments.', categories=[], published_date='2025-08-09T21:24:54Z', pdf_url='https://arxiv.org/pdf/2508.07107v2')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fa2af8d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 3: PDF Download & Caching\n",
      "Testing PDF download for: 2508.07111v1\n",
      "Title: Investigating Intersectional Bias in Large Language Models u...\n",
      "âœ“ PDF downloaded: 2508.07111v1.pdf (6.81 MB)\n"
     ]
    }
   ],
   "source": [
    "# Test PDF Download\n",
    "async def test_pdf_download(test_papers):\n",
    "    \"\"\"Test PDF downloading with caching.\"\"\"\n",
    "\n",
    "    print(\"Test 3: PDF Download & Caching\")\n",
    "    \n",
    "    if not test_papers:\n",
    "        print(\"No papers available for PDF download test\")\n",
    "        return None\n",
    "    \n",
    "    # Test with first paper\n",
    "    test_paper = test_papers[0]\n",
    "    print(f\"Testing PDF download for: {test_paper.arxiv_id}\")\n",
    "    print(f\"Title: {test_paper.title[:60]}...\")\n",
    "    \n",
    "    try:\n",
    "        # Download PDF \n",
    "        pdf_path = await arxiv_client.download_pdf(test_paper)\n",
    "        \n",
    "        if pdf_path and pdf_path.exists():\n",
    "            size_mb = pdf_path.stat().st_size / (1024 * 1024)\n",
    "            print(f\"âœ“ PDF downloaded: {pdf_path.name} ({size_mb:.2f} MB)\")\n",
    "            \n",
    "            return pdf_path\n",
    "        else:\n",
    "            print(\"âœ— PDF download failed\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— PDF download error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Run PDF download test \n",
    "pdf_path = await test_pdf_download(date_papers[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbd27d1",
   "metadata": {},
   "source": [
    "3. Docling PDF Processing\n",
    "Test PDF parsing with Docling for structured content extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcfb40d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 4: PDF Parsing with Docling\n",
      "========================================\n",
      "PDF parser service created\n",
      "Config: 30 pages, 20MB\n",
      "\n",
      "Found 1 PDF files to test parsing\n",
      "Testing PDF parsing with: 2508.07111v1.pdf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter `strict_text` has been deprecated and will be ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ PDF parsing successful!\n",
      "  Sections: 23\n",
      "  Raw text length: 85167 characters\n",
      "  Parser used: ParserType.DOCLING\n",
      "  First section: 'content' (84 chars)\n"
     ]
    }
   ],
   "source": [
    "# Test PDF Parsing with Docling\n",
    "from src.services.pdf_parser.factory import make_pdf_parser_service\n",
    "from src.config import get_settings\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Test 4: PDF Parsing with Docling\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create PDF parser\n",
    "pdf_parser = make_pdf_parser_service()\n",
    "settings = get_settings()\n",
    "print(\"PDF parser service created\")\n",
    "print(f\"Config: {settings.pdf_parser.max_pages} pages, {settings.pdf_parser.max_file_size_mb}MB\")\n",
    "\n",
    "# Test parsing with actual PDF files\n",
    "cache_dir = Path(\"data/arxiv_pdfs\")\n",
    "if cache_dir.exists():\n",
    "    pdf_files = list(cache_dir.glob(\"*.pdf\"))\n",
    "    print(f\"\\nFound {len(pdf_files)} PDF files to test parsing\")\n",
    "    \n",
    "    if pdf_files:\n",
    "        # Test parsing the first PDF\n",
    "        test_pdf = pdf_files[0]\n",
    "        print(f\"Testing PDF parsing with: {test_pdf.name}\")\n",
    "        \n",
    "        try:\n",
    "            pdf_content = await pdf_parser.parse_pdf(test_pdf)\n",
    "            \n",
    "            if pdf_content:\n",
    "                print(f\"âœ“ PDF parsing successful!\")\n",
    "                print(f\"  Sections: {len(pdf_content.sections)}\")\n",
    "                print(f\"  Raw text length: {len(pdf_content.raw_text)} characters\")\n",
    "                print(f\"  Parser used: {pdf_content.parser_used}\")\n",
    "                \n",
    "                # Show first section as example\n",
    "                if pdf_content.sections:\n",
    "                    first_section = pdf_content.sections[0]\n",
    "                    print(f\"  First section: '{first_section.title}' ({len(first_section.content)} chars)\")\n",
    "            else:\n",
    "                print(\"âœ— PDF parsing failed (Docling compatibility issue)\")\n",
    "                print(\"This is expected - not all PDFs work with Docling\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âœ— PDF parsing error: {e}\")\n",
    "            print(\"This demonstrates the error handling in action\")\n",
    "    else:\n",
    "        print(\"No PDF files available for parsing test\")\n",
    "else:\n",
    "    print(\"No PDF cache directory found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b6a5d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 Introduction'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_content.sections[3].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a74371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6a2964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Session rollback because of exception: (psycopg2.errors.UndefinedColumn) column papers.pdf_processing_date does not exist\n",
      "LINE 1: ...ed, papers.parser_metadata, papers.pdf_processed, papers.pdf...\n",
      "                                                             ^\n",
      "HINT:  Perhaps you meant to reference the column \"papers.pdf_processing_data\".\n",
      "\n",
      "[SQL: SELECT papers.id, papers.arxiv_id, papers.title, papers.authors, papers.abstract, papers.categories, papers.published_date, papers.pdf_url, papers.raw_text, papers.\"references\", papers.sections, papers.parser_used, papers.parser_metadata, papers.pdf_processed, papers.pdf_processing_date, papers.created_at, papers.updated_at \n",
      "FROM papers \n",
      "WHERE papers.arxiv_id = %(arxiv_id_1)s]\n",
      "[parameters: {'arxiv_id_1': '2602.16708v1'}]\n",
      "(Background on this error at: https://sqlalche.me/e/20/f405)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 5: Database Storage\n",
      "========================================\n",
      "âœ“ Database connection created\n",
      "Storing paper: 2602.16708v1\n"
     ]
    }
   ],
   "source": [
    "# Test Database Storage\n",
    "from src.db.factory import make_database\n",
    "from src.repositories.paper import PaperRepository\n",
    "from src.schemas.arxiv.paper import PaperCreate\n",
    "from dateutil import parser as date_parser\n",
    "\n",
    "print(\"Test 5: Database Storage\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create database connection\n",
    "database = make_database()\n",
    "print(\"âœ“ Database connection created\")\n",
    "\n",
    "if papers:\n",
    "    test_paper = papers[0]\n",
    "    print(f\"Storing paper: {test_paper.arxiv_id}\")\n",
    "    \n",
    "    try:\n",
    "        with database.get_session() as session:\n",
    "            paper_repo = PaperRepository(session)\n",
    "            \n",
    "            # Convert to database format\n",
    "            published_date = date_parser.parse(test_paper.published_date) if isinstance(test_paper.published_date, str) else test_paper.published_date\n",
    "            \n",
    "            paper_create = PaperCreate(\n",
    "                arxiv_id=test_paper.arxiv_id,\n",
    "                title=test_paper.title,\n",
    "                authors=test_paper.authors,\n",
    "                abstract=test_paper.abstract,\n",
    "                categories=test_paper.categories,\n",
    "                published_date=published_date,\n",
    "                pdf_url=test_paper.pdf_url\n",
    "            )\n",
    "            \n",
    "            # Store paper (upsert to avoid duplicates)\n",
    "            stored_paper = paper_repo.upsert(paper_create)\n",
    "            \n",
    "            if stored_paper:\n",
    "                print(f\"âœ“ Paper stored with ID: {stored_paper.id}\")\n",
    "                print(f\"   Database ID: {stored_paper.id}\")\n",
    "                print(f\"   arXiv ID: {stored_paper.arxiv_id}\")\n",
    "                print(f\"   Title: {stored_paper.title[:50]}...\")\n",
    "                print(f\"   Authors: {len(stored_paper.authors)} authors\")\n",
    "                print(f\"   Categories: {', '.join(stored_paper.categories)}\")\n",
    "                \n",
    "                # Test retrieval\n",
    "                retrieved_paper = paper_repo.get_by_arxiv_id(test_paper.arxiv_id)\n",
    "                if retrieved_paper:\n",
    "                    print(f\"âœ“ Paper retrieval test passed\")\n",
    "                else:\n",
    "                    print(f\"âœ— Paper retrieval failed\")\n",
    "            else:\n",
    "                print(\"âœ— Paper storage failed\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Database error: {e}\")\n",
    "else:\n",
    "    print(\"No papers available for database storage test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a96c6d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Critical error in metadata fetching pipeline: 'downloaded'\n",
      "Pipeline execution: {'papers_fetched': 2, 'papers_downloaded': 0, 'pdf_parsed': 0, 'papers_stored': 0, 'errors': [], 'processing_time': 0.0}.\n",
      "Session rollback because of exception: Critical error in metadata fetching pipeline: 'downloaded'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 6: Complete Metadata Fetcher Pipeline\n",
      "==================================================\n",
      "âœ“ Metadata fetcher service created\n",
      "Running small batch test (2 papers, no PDF processing for speed)...\n",
      "\n",
      "PIPELINE RESULTS:\n",
      "âœ— Pipeline error: name 'results' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Test Complete Pipeline\n",
    "from src.services.metadata_extractor import make_metadata_fetcher\n",
    "\n",
    "print(\"Test 6: Complete Metadata Fetcher Pipeline\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create metadata fetcher\n",
    "metadata_fetcher = make_metadata_fetcher(arxiv_client, pdf_parser)\n",
    "print(\"âœ“ Metadata fetcher service created\")\n",
    "\n",
    "# Test with small batch\n",
    "print(\"Running small batch test (2 papers, no PDF processing for speed)...\")\n",
    "\n",
    "try:\n",
    "    with database.get_session() as session:\n",
    "        results = await metadata_fetcher.fetch_and_process_paper(\n",
    "            max_results=2,  \n",
    "            process_pdf=False,  \n",
    "            store_to_db=True,\n",
    "            db_session=session\n",
    "        )\n",
    "    \n",
    "    print(\"\\nPIPELINE RESULTS:\")\n",
    "    print(f\"   Papers fetched: {results.get('papers_fetched', 0)}\")\n",
    "    print(f\"   PDFs downloaded: {results.get('pdfs_downloaded', 0)}\")\n",
    "    print(f\"   PDFs parsed: {results.get('pdfs_parsed', 0)}\")\n",
    "    print(f\"   Papers stored: {results.get('papers_stored', 0)}\")\n",
    "    print(f\"   Processing time: {results.get('processing_time', 0):.1f}s\")\n",
    "    print(f\"   Errors: {len(results.get('errors', []))}\")\n",
    "    \n",
    "    if results.get('errors'):\n",
    "        print(\"\\nErrors encountered:\")\n",
    "        for error in results.get('errors', [])[:3]:  # Show first 3 errors\n",
    "            print(f\"   - {error}\")\n",
    "    \n",
    "    if results.get('papers_fetched', 0) > 0:\n",
    "        print(\"\\nâœ“ Pipeline test successful!\")\n",
    "    else:\n",
    "        print(\"\\nNo papers fetched - may be arXiv API unavailability\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Pipeline error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArXivPaperCurator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
