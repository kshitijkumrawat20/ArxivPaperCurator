{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f45aadbe",
   "metadata": {},
   "source": [
    "## Phase 2: arXiv API Integration & PDF Processing\n",
    "\n",
    "### Core Objectives\n",
    "- arXiv API Integration: Build a robust client with rate limiting and retry logic\n",
    "- PDF Processing Pipeline: Download and parse scientific PDFs with structured content extraction\n",
    "- Database Storage: Persist paper metadata and content in PostgreSQL\n",
    "- Error Handling: Implement comprehensive error handling and graceful degradation\n",
    "- Automation Ready: Prepare components for Airflow orchestration\n",
    "\n",
    "### ðŸ”§ What We'll Test In This Notebook\n",
    "- arXiv API Client - Fetch CS.AI papers with proper rate limiting\n",
    "- PDF Download System - Download and cache PDFs with error handling\n",
    "- Docling PDF Parser - Extract structured content (sections, tables, figures)\n",
    "- Database Integration - Store and retrieve papers from PostgreSQL\n",
    "- Complete Pipeline - End-to-end processing from arXiv to database\n",
    "- Production Readiness - Error handling, logging, and performance metrics\n",
    "### ðŸ“Š Success Metrics\n",
    "- arXiv API calls succeed with proper rate limiting\n",
    "- PDF download and caching works reliably\n",
    "- Docling extracts structured content from scientific PDFs\n",
    "- Database stores complete paper metadata\n",
    "- Pipeline handles errors gracefully and continues processing\n",
    "- All components ready for Airflow automation (Week 2+)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7b7d7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WEEK 2 CONTAINER & SERVICE HEALTH CHECK\n",
      "==================================================\n",
      "Project root: /teamspace/studios/this_studio/ArxivPaperCurator\n"
     ]
    }
   ],
   "source": [
    "# Check if Fresh Containers are Built and All Services Healthy\n",
    "import subprocess\n",
    "import requests\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"WEEK 2 CONTAINER & SERVICE HEALTH CHECK\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Find project root\n",
    "current_dir = Path.cwd()\n",
    "if current_dir.name == \"notebooks\" and current_dir.parent.name == \"ArxivPaperCurator\":\n",
    "    project_root = current_dir.parent\n",
    "elif (current_dir / \"compose.yml\").exists():\n",
    "    project_root = current_dir\n",
    "else:\n",
    "    print(\"âœ— Could not find project root\")\n",
    "    exit()\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.12.11\n",
      "Environment: /home/zeus/miniconda3/envs/cloudspace/bin/python\n"
     ]
    }
   ],
   "source": [
    "# Environment Check\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"Python Version: {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")\n",
    "print(f\"Environment: {sys.executable}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4153c8e5",
   "metadata": {},
   "source": [
    "### Service Health Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e526f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Checking container status...\n",
      "âœ“ Containers are running:\n",
      "   NAME                        IMAGE                                            COMMAND                   SERVICE                 CREATED          STATUS                     PORTS\n",
      "   rag-airflow                 apache/airflow:3.0.3                             \"/bin/bash -c '\\n  piâ€¦\"   airflow                 11 minutes ago   Up 7 minutes (unhealthy)   0.0.0.0:8080->8080/tcp, :::8080->8080/tcp\n",
      "   rag-api                     arxivpapercurator-api                            \"uvicorn src.main:apâ€¦\"    api                     11 minutes ago   Up 7 minutes (unhealthy)   0.0.0.0:8000->8000/tcp, :::8000->8000/tcp\n",
      "   rag-ollama                  ollama/ollama:0.11.2                             \"/bin/ollama serve\"       ollama                  11 minutes ago   Up 7 minutes (healthy)     0.0.0.0:11434->11434/tcp, :::11434->11434/tcp\n",
      "   rag-opensearch              opensearchproject/opensearch:2.19.0              \"./opensearch-dockerâ€¦\"    opensearch              11 minutes ago   Up 7 minutes (healthy)     0.0.0.0:9200->9200/tcp, :::9200->9200/tcp, 9300/tcp, 0.0.0.0:9600->9600/tcp, :::9600->9600/tcp, 9650/tcp\n",
      "   rag-opensearch-dashboards   opensearchproject/opensearch-dashboards:2.19.0   \"./opensearch-dashboâ€¦\"    opensearch-dashboards   11 minutes ago   Up 7 minutes (healthy)     0.0.0.0:5601->5601/tcp, :::5601->5601/tcp\n",
      "   rag-postgres                postgres:16-alpine                               \"docker-entrypoint.sâ€¦\"    postgres                11 minutes ago   Up 7 minutes (healthy)     0.0.0.0:5432->5432/tcp, :::5432->5432/tcp\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Check if containers are built and running\n",
    "print(\"\\n1. Checking container status...\")\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        [\"docker\", \"compose\", \"ps\", \"--format\", \"table\"],\n",
    "        cwd=str(project_root),\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=10\n",
    "    )\n",
    "    \n",
    "    if result.returncode == 0 and result.stdout.strip():\n",
    "        print(\"âœ“ Containers are running:\")\n",
    "        for line in result.stdout.strip().split('\\n'):\n",
    "            print(f\"   {line}\")\n",
    "    else:\n",
    "        print(\"âœ— No containers running or docker compose failed\")\n",
    "        print(\"Please run the build commands from the markdown cell above\")\n",
    "        exit()\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error checking containers: {e}\")\n",
    "    print(\"Please run the build commands from the markdown cell above\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2. Checking service health...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ FastAPI: Healthy\n",
      "âœ“ PostgreSQL (via API): Healthy\n",
      "âœ“ Ollama: Healthy\n",
      "âœ“ OpenSearch: Healthy\n",
      "âœ“ Airflow: Healthy\n",
      "\n",
      "==================================================\n",
      "âœ“ ALL SERVICES HEALTHY! Ready for Week 2 development.\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Check all service health (corrected endpoints)\n",
    "print(\"\\n2. Checking service health...\")\n",
    "services_to_test = {\n",
    "    \"FastAPI\": \"https://8000-01khp40rhz7zc0vjm8t9gsh5j1.cloudspaces.litng.ai/api/v1/ping/health\",\n",
    "    \"PostgreSQL (via API)\": \"https://8000-01khp40rhz7zc0vjm8t9gsh5j1.cloudspaces.litng.ai/api/v1/ping/health\", \n",
    "    \"Ollama\": \"https://11434-01khp40rhz7zc0vjm8t9gsh5j1.cloudspaces.litng.ai/api/version\",\n",
    "    \"OpenSearch\": \"https://9200-01khp40rhz7zc0vjm8t9gsh5j1.cloudspaces.litng.ai/_cluster/health\",\n",
    "    \"Airflow\": \"https://8080-01khp40rhz7zc0vjm8t9gsh5j1.cloudspaces.litng.ai/api/v2/monitor/health\"\n",
    "}\n",
    "\n",
    "all_healthy = True\n",
    "for service_name, url in services_to_test.items():\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        if response.status_code == 200:\n",
    "            print(f\"âœ“ {service_name}: Healthy\")\n",
    "        else:\n",
    "            print(f\"âœ— {service_name}: HTTP {response.status_code}\")\n",
    "            all_healthy = False\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        print(f\"âœ— {service_name}: Not accessible\")\n",
    "        all_healthy = False\n",
    "    except Exception as e:\n",
    "        print(f\"âœ— {service_name}: {type(e).__name__}\")\n",
    "        all_healthy = False\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "if all_healthy:\n",
    "    print(\"âœ“ ALL SERVICES HEALTHY! Ready for Week 2 development.\")\n",
    "else:\n",
    "    print(\"âœ— Some services need attention.\")\n",
    "    print(\"If you just rebuilt containers, wait 1-2 minutes and run this cell again.\")\n",
    "    print(\"Airflow and OpenSearch take longest to start up.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "airflow_password = \"FkfGnM9ZPup7YTre\"\n",
    "airflow_usernmae = \"admin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71938182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/ArxivPaperCurator\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a5276f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING ARXIV API CLIENT\n",
      "========================================\n",
      "âœ“ Client created: https://export.arxiv.org/api/query\n",
      "   Rate limit: 3.0s\n",
      "   Max results: 100\n",
      "   Category: cs.AI\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Import our arXiv client\n",
    "from src.services.arxiv.factory import make_arxiv_client\n",
    "\n",
    "print(\"TESTING ARXIV API CLIENT\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create client\n",
    "arxiv_client = make_arxiv_client()\n",
    "print(f\"âœ“ Client created: {arxiv_client.base_url}\")\n",
    "print(f\"   Rate limit: {arxiv_client.rate_limit_delay}s\")\n",
    "print(f\"   Max results: {arxiv_client.max_results_per_query}\")\n",
    "print(f\"   Category: {arxiv_client.search_category}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3c1feae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: Fetch Recent CS.AI Papers\n",
      "âœ“ Fetched 0 papers\n"
     ]
    }
   ],
   "source": [
    "async def test_paper_fetching():\n",
    "    \"\"\"Test fetching papers from arXiv with rate limiting.\"\"\"\n",
    "    \n",
    "    print(\"Test 1: Fetch Recent CS.AI Papers\")\n",
    "    try:\n",
    "        papers = await arxiv_client.fetch_papers(\n",
    "            max_results=2, \n",
    "            sort_by=\"submittedDate\",\n",
    "            sort_order=\"descending\"\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ“ Fetched {len(papers)} papers\")\n",
    "        \n",
    "        if papers:\n",
    "            for i, paper in enumerate(papers[:2], 1):\n",
    "                print(f\"   {i}. [{paper.arxiv_id}] {paper.title[:60]}...\")\n",
    "                print(f\"      Authors: {', '.join(paper.authors[:2])}{'...' if len(paper.authors) > 2 else ''}\")\n",
    "                print(f\"      Categories: {', '.join(paper.categories)}\")\n",
    "                print(f\"      Published: {paper.published_date}\")\n",
    "                print()\n",
    "        \n",
    "        return papers\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Error fetching papers: {e}\")\n",
    "        if \"503\" in str(e):\n",
    "            print(\"   arXiv API temporarily unavailable (normal)\")\n",
    "            print(\"   Rate limiting and error handling working correctly\")\n",
    "        return []\n",
    "\n",
    "# Run the test\n",
    "papers = await test_paper_fetching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "102a4af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 2: Date Range Filtering\n",
      "âœ“ Date filtering test: 0 papers from 20250808-20260201\n"
     ]
    }
   ],
   "source": [
    "# Test Date Filtering\n",
    "async def test_date_filtering():\n",
    "    \"\"\"Test date range filtering functionality.\"\"\"\n",
    "    \n",
    "    print(\"Test 2: Date Range Filtering\")\n",
    "    \n",
    "    # Use specific dates: \n",
    "    from_date = \"20250808\"  \n",
    "    to_date = \"20260201\"    \n",
    "    try:\n",
    "        date_papers = await arxiv_client.fetch_papers(\n",
    "            max_results=5,\n",
    "            from_date=from_date,\n",
    "            to_date=to_date\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ“ Date filtering test: {len(date_papers)} papers from {from_date}-{to_date}\")\n",
    "        \n",
    "        if date_papers:\n",
    "            for i, paper in enumerate(date_papers, 1):\n",
    "                print(f\"   {i}. [{paper.arxiv_id}] {paper.title[:60]}...\")\n",
    "                print(f\"      Authors: {', '.join(paper.authors[:2])}{'...' if len(paper.authors) > 2 else ''}\")\n",
    "                print(f\"      Categories: {', '.join(paper.categories)}\")\n",
    "                print(f\"      Published: {paper.published_date}\")\n",
    "                print()\n",
    "        \n",
    "        return date_papers\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âœ— Date filtering error: {e}\")\n",
    "        return []\n",
    "\n",
    "# Run date filtering test\n",
    "date_papers = await test_date_filtering()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArXivPaperCurator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
